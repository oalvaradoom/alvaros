{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp, OpenAI, GPT4All \n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ./llama.cpp/models/7B/ggml-model-q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v1 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =  59.11 KB\n",
      "llama_model_load_internal: mem required  = 5809.32 MB (+ 2052.00 MB per state)\n",
      "llama_init_from_file: kv self size  =  512.00 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(model_path=\"./llama.cpp/models/7B/ggml-model-q4_0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Pregunta: {question}\n",
    "\n",
    "Respuesta: Pensemos paso a paso\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2778.46 ms\n",
      "llama_print_timings:      sample time =   231.75 ms /   256 runs   (    0.91 ms per run)\n",
      "llama_print_timings: prompt eval time =  2267.80 ms /    23 tokens (   98.60 ms per token)\n",
      "llama_print_timings:        eval time = 21747.97 ms /   255 runs   (   85.29 ms per run)\n",
      "llama_print_timings:       total time = 24277.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "', para el que le interese preparar una quesadilla, por ejemplo, en México se puede hacer con una forma especial de tortilla de maíz (que no es un sándwich ni una taco ni una tostada), hecha con harina y masa madre (yehualteco, como se llama aquí, para que los que no lo conocen puedan leer el etiqueta).\\nY en esta quesadilla que es la base de la receta, al lado derecho hay un plato de maíz con leche y queso fresco en la parte interna.\\nEntonces para ponerle masa madre primero se deshace el queso, se forma una bola (dejando la cáscara), y luego se convierte en tortilla o masa. Entonces se pone un poco de aceite de oliva y enseguida se echa la masa para que no se seque. A continuación se coloca un poco de queso derretido por encima del resto de masa hasta que termina.\\nLa forma es circular, con la mitad superior de la masa como una cap'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Como preparo una quesadilla\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
